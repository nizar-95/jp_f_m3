{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse a pdf file\n",
    "# read the file then transform to pandas dataFrame\n",
    "# split the text into sentenses\n",
    "# cleaning the data , and set them in consistence Format\n",
    "# add new colomuns , for the length of characters and words in each sentences\n",
    "# set the  Average Word Length\n",
    "# use CountVectorizer to build a matrix of token counts\n",
    "# use TfidfVectorizer to calculate the Frequency of each token in the Text\n",
    "# use n gramm to represent sequences of words or characters in a text document. \n",
    "# get the commun used word in the text\n",
    "# set a trigram features , to know the most commun words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8490efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 #  need it to read the pdf file\n",
    "import pandas as pd # need it to tranforom into cdv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69068f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = open('Chan2014a.pdf', 'rb')\n",
    "\n",
    "# Create a PDF reader object\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "# Extract text from the PDF file\n",
    "text = ''\n",
    "\n",
    "# for page_num in range(pdf_reader.getNumPages()):\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    page = pdf_reader.pages[page_num]\n",
    "    text += page.extract_text()\n",
    "    \n",
    "    \n",
    "    # split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "# create a pandas DataFrame from the sentences\n",
    "df = pd.DataFrame(sentences, columns=['Sentences'])\n",
    "# df_t = pd.DataFrame(sentences, columns=['text'])\n",
    "pdf_file.close()\n",
    "# write the DataFrame to a CSV file\n",
    "df.to_csv('output_file.csv', index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2a2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NIZAR\\AppData\\Local\\Temp/ipykernel_40392/1531420399.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"Sentences\"] = df[\"Sentences\"].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       Thirty Fifth International Conference on In...\n",
       "1    The exponential gro wth of this nascent online...\n",
       "2    Despite this importance   limited effort has b...\n",
       "3    Using a novel proprietary  dataset from a lead...\n",
       "4    After accounting fo r endogeneity via a matche...\n",
       "Name: Sentences, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove none text characters from text column\n",
    "df[\"Sentences\"] = df[\"Sentences\"].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "df[\"Sentences\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbb8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   thirty fifth international conference on informati on systems  auckland        hiring biases in online labor markets     the case of gender stereotyping   completed research paper      jason chan   carlson school of management   university of minnesota         th  ave south  minneapolis    mn        united states  jchancf umn edu jing wang   school of business and management   hkust  lee shau kee business building    clear water bay  kowloon  hong kong  jwang ust hk    abstract  online labor marketplaces facilitate the efficient matching of employers and workers  across geographical boundaries'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Made all charactuers lowercase\n",
    "df[\"Sentences\"] = df[\"Sentences\"].str.lower()\n",
    "df[\"Sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c493e85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Char Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirty fifth international conference on in...</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the exponential gro wth of this nascent online...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>despite this importance   limited effort has b...</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using a novel proprietary  dataset from a lead...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after accounting fo r endogeneity via a matche...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Char Len\n",
       "0     thirty fifth international conference on in...       603\n",
       "1  the exponential gro wth of this nascent online...       108\n",
       "2  despite this importance   limited effort has b...       174\n",
       "3  using a novel proprietary  dataset from a lead...       147\n",
       "4  after accounting fo r endogeneity via a matche...       188"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of Characters\n",
    "df[\"Char Len\"] = df[\"Sentences\"].str.len()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbbde412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Char Len</th>\n",
       "      <th>Words Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirty fifth international conference on in...</td>\n",
       "      <td>603</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the exponential gro wth of this nascent online...</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>despite this importance   limited effort has b...</td>\n",
       "      <td>174</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using a novel proprietary  dataset from a lead...</td>\n",
       "      <td>147</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after accounting fo r endogeneity via a matche...</td>\n",
       "      <td>188</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Char Len  Words Len\n",
       "0     thirty fifth international conference on in...       603         79\n",
       "1  the exponential gro wth of this nascent online...       108         16\n",
       "2  despite this importance   limited effort has b...       174         27\n",
       "3  using a novel proprietary  dataset from a lead...       147         23\n",
       "4  after accounting fo r endogeneity via a matche...       188         29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of Words\n",
    "df[\"Words Len\"] = df[\"Sentences\"].str.split().str.len()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6330f16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Char Len</th>\n",
       "      <th>Words Len</th>\n",
       "      <th>Avg Word Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirty fifth international conference on in...</td>\n",
       "      <td>603</td>\n",
       "      <td>79</td>\n",
       "      <td>7.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the exponential gro wth of this nascent online...</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Char Len  Words Len  \\\n",
       "0     thirty fifth international conference on in...       603         79   \n",
       "1  the exponential gro wth of this nascent online...       108         16   \n",
       "\n",
       "   Avg Word Len  \n",
       "0          7.63  \n",
       "1          6.75  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Word Length\n",
    "df[\"Avg Word Len\"] = (df[\"Char Len\"] / df[\"Words Len\"]).round(2)\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d7a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Vectorizer\n",
    "# CountVectorizer is a text feature extraction tool provided by scikit-learn that can be used \n",
    "# to convert a collection of text documents into a matrix of token counts. \n",
    "# This matrix can then be used for various text analysis tasks such as text classification, clustering, or information retrieval.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df = 0.1, max_df = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbcedcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<638x16 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2029 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_transform = cv.fit_transform(df[\"Sentences\"])\n",
    "cv_transform[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5ebac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_and</th>\n",
       "      <th>Count_are</th>\n",
       "      <th>Count_for</th>\n",
       "      <th>Count_gender</th>\n",
       "      <th>Count_hiring</th>\n",
       "      <th>Count_in</th>\n",
       "      <th>Count_is</th>\n",
       "      <th>Count_labor</th>\n",
       "      <th>Count_of</th>\n",
       "      <th>Count_on</th>\n",
       "      <th>Count_online</th>\n",
       "      <th>Count_that</th>\n",
       "      <th>Count_the</th>\n",
       "      <th>Count_to</th>\n",
       "      <th>Count_we</th>\n",
       "      <th>Count_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count_and  Count_are  Count_for  Count_gender  Count_hiring  Count_in  \\\n",
       "0          2          0          0             1             1         1   \n",
       "1          1          0          0             0             0         0   \n",
       "2          1          0          0             0             2         1   \n",
       "3          0          0          0             1             1         1   \n",
       "4          1          0          0             0             1         0   \n",
       "\n",
       "   Count_is  Count_labor  Count_of  Count_on  Count_online  Count_that  \\\n",
       "0         0            2         5         2             2           0   \n",
       "1         0            0         1         0             1           0   \n",
       "2         0            1         0         0             1           0   \n",
       "3         0            1         1         1             1           0   \n",
       "4         0            0         1         0             0           0   \n",
       "\n",
       "   Count_the  Count_to  Count_we  Count_workers  \n",
       "0          2         0         0              1  \n",
       "1          1         0         0              0  \n",
       "2          0         1         0              0  \n",
       "3          1         0         1              0  \n",
       "4          1         0         1              1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A unique token is a token type that occurs only once in a given corpus of text, \n",
    "# whereas a token is an instance of a token type that occurs one or more times in the corpus.\n",
    "\n",
    "cv_df = pd.DataFrame(cv_transform.toarray(),\n",
    "                     columns = cv.get_feature_names()).add_prefix(\"Count_\")\n",
    "cv_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1842887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_df = pd.concat([df, cv_df], axis = 1)\n",
    "speech_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feca2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(max_features=100, stop_words='english')\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF is calculated by multiplying the term frequency (TF) of a term in a document \n",
    "# by its inverse document frequency (IDF) across all documents in the corpus. \n",
    "# The term frequency measures how often a term appears in a document,\n",
    "# while the inverse document frequency measures how rare or unique a term is across all documents in the corpus.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(max_features = 100, stop_words = \"english\")\n",
    "print(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc163b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Char Len</th>\n",
       "      <th>Words Len</th>\n",
       "      <th>Avg Word Len</th>\n",
       "      <th>TFIDF_al</th>\n",
       "      <th>TFIDF_applicant</th>\n",
       "      <th>TFIDF_applicants</th>\n",
       "      <th>TFIDF_attributes</th>\n",
       "      <th>TFIDF_auckland</th>\n",
       "      <th>TFIDF_based</th>\n",
       "      <th>...</th>\n",
       "      <th>TFIDF_use</th>\n",
       "      <th>TFIDF_used</th>\n",
       "      <th>TFIDF_using</th>\n",
       "      <th>TFIDF_utility</th>\n",
       "      <th>TFIDF_value</th>\n",
       "      <th>TFIDF_variable</th>\n",
       "      <th>TFIDF_women</th>\n",
       "      <th>TFIDF_worker</th>\n",
       "      <th>TFIDF_workers</th>\n",
       "      <th>TFIDF_working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirty fifth international conference on in...</td>\n",
       "      <td>603</td>\n",
       "      <td>79</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the exponential gro wth of this nascent online...</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>despite this importance   limited effort has b...</td>\n",
       "      <td>174</td>\n",
       "      <td>27</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using a novel proprietary  dataset from a lead...</td>\n",
       "      <td>147</td>\n",
       "      <td>23</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after accounting fo r endogeneity via a matche...</td>\n",
       "      <td>188</td>\n",
       "      <td>29</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Char Len  Words Len  \\\n",
       "0     thirty fifth international conference on in...       603         79   \n",
       "1  the exponential gro wth of this nascent online...       108         16   \n",
       "2  despite this importance   limited effort has b...       174         27   \n",
       "3  using a novel proprietary  dataset from a lead...       147         23   \n",
       "4  after accounting fo r endogeneity via a matche...       188         29   \n",
       "\n",
       "   Avg Word Len  TFIDF_al  TFIDF_applicant  TFIDF_applicants  \\\n",
       "0          7.63       0.0              0.0               0.0   \n",
       "1          6.75       0.0              0.0               0.0   \n",
       "2          6.44       0.0              0.0               0.0   \n",
       "3          6.39       0.0              0.0               0.0   \n",
       "4          6.48       0.0              0.0               0.0   \n",
       "\n",
       "   TFIDF_attributes  TFIDF_auckland  TFIDF_based  ...  TFIDF_use  TFIDF_used  \\\n",
       "0               0.0        0.201833     0.000000  ...        0.0         0.0   \n",
       "1               0.0        0.000000     0.000000  ...        0.0         0.0   \n",
       "2               0.0        0.000000     0.000000  ...        0.0         0.0   \n",
       "3               0.0        0.000000     0.362069  ...        0.0         0.0   \n",
       "4               0.0        0.000000     0.000000  ...        0.0         0.0   \n",
       "\n",
       "   TFIDF_using  TFIDF_utility  TFIDF_value  TFIDF_variable  TFIDF_women  \\\n",
       "0     0.000000            0.0          0.0             0.0          0.0   \n",
       "1     0.000000            0.0          0.0             0.0          0.0   \n",
       "2     0.000000            0.0          0.0             0.0          0.0   \n",
       "3     0.356244            0.0          0.0             0.0          0.0   \n",
       "4     0.000000            0.0          0.0             0.0          0.0   \n",
       "\n",
       "   TFIDF_worker  TFIDF_workers  TFIDF_working  \n",
       "0           0.0       0.142481            0.0  \n",
       "1           0.0       0.000000            0.0  \n",
       "2           0.0       0.000000            0.0  \n",
       "3           0.0       0.000000            0.0  \n",
       "4           0.0       0.247409            0.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_transformed = tv.fit_transform(df[\"Sentences\"])\n",
    "\n",
    "tv_df = pd.DataFrame(tv_transformed.toarray(),\n",
    "                     columns = tv.get_feature_names()).add_prefix(\"TFIDF_\")\n",
    "\n",
    "tvdf_trans = pd.concat([df, tv_df], axis = 1)\n",
    "tvdf_trans[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f7d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF_management      0.455590\n",
      "TFIDF_labor           0.286252\n",
      "TFIDF_online          0.247873\n",
      "TFIDF_stereotyping    0.223585\n",
      "TFIDF_research        0.223585\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Isolate the row to be examined\n",
    "sample_row = tv_df.iloc[0]\n",
    "# Print the top 5 words of the sorted output\n",
    "print(sample_row.sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1700412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_TFIDF_al</th>\n",
       "      <th>Train_TFIDF_applicant</th>\n",
       "      <th>Train_TFIDF_applicants</th>\n",
       "      <th>Train_TFIDF_attributes</th>\n",
       "      <th>Train_TFIDF_auckland</th>\n",
       "      <th>Train_TFIDF_based</th>\n",
       "      <th>Train_TFIDF_bias</th>\n",
       "      <th>Train_TFIDF_biases</th>\n",
       "      <th>Train_TFIDF_caliper</th>\n",
       "      <th>Train_TFIDF_category</th>\n",
       "      <th>...</th>\n",
       "      <th>Train_TFIDF_use</th>\n",
       "      <th>Train_TFIDF_used</th>\n",
       "      <th>Train_TFIDF_using</th>\n",
       "      <th>Train_TFIDF_utility</th>\n",
       "      <th>Train_TFIDF_value</th>\n",
       "      <th>Train_TFIDF_variable</th>\n",
       "      <th>Train_TFIDF_women</th>\n",
       "      <th>Train_TFIDF_worker</th>\n",
       "      <th>Train_TFIDF_workers</th>\n",
       "      <th>Train_TFIDF_working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_TFIDF_al  Train_TFIDF_applicant  Train_TFIDF_applicants  \\\n",
       "0             0.0                    0.0                     0.0   \n",
       "1             0.0                    0.0                     0.0   \n",
       "2             0.0                    0.0                     0.0   \n",
       "3             0.0                    0.0                     0.0   \n",
       "4             0.0                    0.0                     0.0   \n",
       "\n",
       "   Train_TFIDF_attributes  Train_TFIDF_auckland  Train_TFIDF_based  \\\n",
       "0                     0.0              0.201833           0.000000   \n",
       "1                     0.0              0.000000           0.000000   \n",
       "2                     0.0              0.000000           0.000000   \n",
       "3                     0.0              0.000000           0.362069   \n",
       "4                     0.0              0.000000           0.000000   \n",
       "\n",
       "   Train_TFIDF_bias  Train_TFIDF_biases  Train_TFIDF_caliper  \\\n",
       "0          0.000000            0.177822                  0.0   \n",
       "1          0.000000            0.000000                  0.0   \n",
       "2          0.000000            0.496865                  0.0   \n",
       "3          0.000000            0.000000                  0.0   \n",
       "4          0.299468            0.000000                  0.0   \n",
       "\n",
       "   Train_TFIDF_category  ...  Train_TFIDF_use  Train_TFIDF_used  \\\n",
       "0                   0.0  ...              0.0               0.0   \n",
       "1                   0.0  ...              0.0               0.0   \n",
       "2                   0.0  ...              0.0               0.0   \n",
       "3                   0.0  ...              0.0               0.0   \n",
       "4                   0.0  ...              0.0               0.0   \n",
       "\n",
       "   Train_TFIDF_using  Train_TFIDF_utility  Train_TFIDF_value  \\\n",
       "0           0.000000                  0.0                0.0   \n",
       "1           0.000000                  0.0                0.0   \n",
       "2           0.000000                  0.0                0.0   \n",
       "3           0.356244                  0.0                0.0   \n",
       "4           0.000000                  0.0                0.0   \n",
       "\n",
       "   Train_TFIDF_variable  Train_TFIDF_women  Train_TFIDF_worker  \\\n",
       "0                   0.0                0.0                 0.0   \n",
       "1                   0.0                0.0                 0.0   \n",
       "2                   0.0                0.0                 0.0   \n",
       "3                   0.0                0.0                 0.0   \n",
       "4                   0.0                0.0                 0.0   \n",
       "\n",
       "   Train_TFIDF_workers  Train_TFIDF_working  \n",
       "0             0.142481                  0.0  \n",
       "1             0.000000                  0.0  \n",
       "2             0.000000                  0.0  \n",
       "3             0.000000                  0.0  \n",
       "4             0.247409                  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The TF-IDF weighting scheme is used to measure the importance or relevance of a term \n",
    "# (i.e., a word or phrase) in a document, \n",
    "# relative to its frequency in the entire corpus of documents.\n",
    "tv = TfidfVectorizer(max_features = 100, stop_words = \"english\")\n",
    "\n",
    "# Fit the vectroizer and transform the data\n",
    "tv_transformed = tv.fit_transform(df[\"Sentences\"])\n",
    "\n",
    "# Transform  data\n",
    "tv_transformed = pd.DataFrame(tv_transformed.toarray(),\n",
    "                                   columns = tv.get_feature_names()).add_prefix(\"Train_TFIDF_\")\n",
    "tv_transformed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42c6589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act of workers gender on hiring',\n",
       " 'act of workers gender on hiring outcomes',\n",
       " 'act of workers gender on hiring outcomes in',\n",
       " 'actions implicate the income',\n",
       " 'actions implicate the income of',\n",
       " 'actions implicate the income of millions',\n",
       " 'actions implicate the income of millions of',\n",
       " 'actions implicate the income of millions of workers',\n",
       " 'active projects and workers',\n",
       " 'actual working hours online']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n gramm\n",
    "# represent sequences of words or characters in a text document. \n",
    "# An n-gram is a contiguous sequence of n items from a given sequence of text, \n",
    "# where an item can be a word, a character, or a subword unit.\n",
    "# for Train_set\n",
    "tv_bi_gram_vec = TfidfVectorizer(ngram_range = (4, 8))\n",
    "\n",
    "tv_bi_gram = tv_bi_gram_vec.fit_transform(df[\"Sentences\"])\n",
    "\n",
    "tv_bi_gram_vec.get_feature_names()[300:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4ea5801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counts_ab le to infer                              0.077951\n",
       "Counts_ab le to infer the                          0.077951\n",
       "Counts_ab le to infer the gender                   0.077951\n",
       "Counts_ab le to infer the gender information       0.077951\n",
       "Counts_ab le to infer the gender information of    0.077951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with Count Features\n",
    "tv_df = pd.DataFrame(tv_bi_gram.toarray(),\n",
    "                     columns = tv_bi_gram_vec.get_feature_names()).add_prefix(\"Counts_\")\n",
    "\n",
    "tv_sums = tv_df.sum()\n",
    "\n",
    "tv_sums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9be678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counts_quarterly journal of economics              4.118816\n",
       "Counts_journal of applied psychology               2.000000\n",
       "Counts_journal of economic perspectives            2.000000\n",
       "Counts_the american economic review                2.000000\n",
       "Counts_thirty fifth international conference on    1.000677\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common Words\n",
    "tv_sums.sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aeb452f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american economic review', 'biases online labor', 'biases online labor markets', 'biases online labor markets thirty', 'checkbld checkbld checkbld', 'checkbld checkbld checkbld checkbld', 'checkbld checkbld checkbld checkbld checkbld', 'checkbld checkbld log likelihood', 'checkbld checkbld log likelihood observations', 'checkbld checkbld matched', 'checkbld checkbld matched workers', 'checkbld checkbld matched workers job', 'checkbld log likelihood', 'checkbld log likelihood observations', 'checkbld matched workers', 'checkbld matched workers job', 'checkbld matched workers job posting', 'conditional logistic regressions', 'conference informatio systems', 'conference informatio systems auckland', 'economics value thirty', 'economics value thirty fifth', 'economics value thirty fifth international', 'feminine neutral masculine', 'fifth international conference', 'fifth international conference informatio', 'fifth international conference informatio systems', 'hiring biases online', 'hiring biases online labor', 'hiring biases online labor markets', 'hiring decisions online', 'importance worker gender', 'informatio systems auckland', 'information asymmetry issues', 'international conference informatio', 'international conference informatio systems', 'international conference informatio systems auckland', 'job category checkbld', 'job category checkbld checkbld', 'job category checkbld checkbld matched', 'job posting checkbld', 'job posting checkbld checkbld', 'job posting checkbld checkbld log', 'job posting fixed', 'job posting fixed effects', 'labor markets thirty', 'labor markets thirty fifth', 'labor markets thirty fifth international', 'level significance level', 'likelihood observations notes', 'likelihood observations notes models', 'log likelihood observations', 'logistic regressions wi th job', 'making hiring decisions', 'markets thirty fifth', 'markets thirty fifth international', 'markets thirty fifth international conference', 'matched job category', 'matched sample approach', 'matched workers job', 'models conditional logistic', 'models conditional logistic regressions', 'models conditional logistic regressions wi', 'notes models conditional', 'notes models conditional logistic', 'notes models conditional logistic regressions', 'observations notes models', 'observations notes models conditional', 'observations notes models conditional logistic', 'online labor market', 'online labor marketplaces', 'online labor markets', 'online labor markets thirty', 'online labor markets thirty fifth', 'online labor platform', 'organizational behavior human decision', 'posting fixed effects', 'quarterly journal economics', 'reflecting importance worker', 'reflecting importance worker gender', 'regressions wi th', 'regressions wi th job posting', 'significance level significance', 'significance level significance level', 'thirty fifth international', 'thirty fifth international conference', 'thirty fifth international conference informatio', 'traditional labor markets', 'utility weight reflecting', 'utility weight reflecting importance', 'value thirty fifth', 'value thirty fifth international', 'value thirty fifth international conference', 'weight reflecting importance', 'workers job category', 'workers job category checkbld', 'workers job category checkbld checkbld', 'workers job posting', 'workers job posting checkbld', 'workers job posting checkbld checkbld']\n"
     ]
    }
   ],
   "source": [
    "#Using longer n-grams\n",
    "# Instantiate a trigram vectorizer\n",
    "cv_trigram_vec = CountVectorizer(max_features = 100,\n",
    "                                 stop_words = \"english\",\n",
    "                                 ngram_range = (3, 5))\n",
    "\n",
    "# Fit and apply trigram vectorizer\n",
    "cv_trigram = cv_trigram_vec.fit_transform(df[\"Sentences\"])\n",
    "\n",
    "# Print the trigram features\n",
    "print(cv_trigram_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baaa0a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counts_online labor markets                           25\n",
       "Counts_thirty fifth international                     17\n",
       "Counts_thirty fifth international conference          17\n",
       "Counts_fifth international conference                 17\n",
       "Counts_international conference informatio systems    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the most commun word\n",
    "cv_tri_df = pd.DataFrame(cv_trigram.toarray(),\n",
    "                         columns = cv_trigram_vec.get_feature_names()).add_prefix(\"Counts_\")\n",
    "\n",
    "# Print the top 5 words in the sorted output\n",
    "cv_tri_df.sum().sort_values(ascending = False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
